{
  "metadata": {
    "name": "00-va-App 0.2.7.6.b",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nprintln(\"%html \u003ca href\u003d\\\"http://sensoranalytics.com.au/\\\"\u003e\u003cimg src\u003d\\\"http://sensoranalytics.com.au/assets/images/title.png\\\" width\u003d\\\"50\\\" height\u003d\\\"50\\\" \u003e\u003c/a\u003e\")\nprintln(\"\u003ch3 style\u003d\\\"color:grey\\\";\u003e Video Analytics App @134 px\u003c/h3\u003e\u003ch7\u003e\u003ca href\u003d\\\"http://sensoranalytics.com.au/\\\"\u003eby Sensor Analytics Australia\u003c/h7\u003e\u003c/a\u003e\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### About\n###### This app is for discovering anomalies in video scenes. Anomaly detection is a different problem to motion detection. For anomaly detection, a scene may be continually changing e.g. something moving in the breeze or background motion yet a fundamental change to the scene (an anonmaly) can still be detected.\n### Instructions\n###### [1] JPG frames extracted from any video clip to be analaysed should be uploaded into this vm into saauser@bigvm2:~/upload/your_folder_name  (ffmpeg -i myvideo.mp4 -r 1 myvideofms%03d.jpg)\n###### [2] The above path needs to be specfied in *\u0027Load Frames\u0027* \n###### [3] *Kmeans* *numCluster* can be set as 2, 3, so on in  **\u0027Kmeans\u0027**. Choice of numClusters is data dependent, however generally a value between 3 to 6 that maximises the *Silhouette with squared euclidean distance* should be a good starting point. In the absence of small clusters, *numCluster* should be gradaually increased until few small clusters (members\u003c5) appear. Anomalous images are likely to occur in the few smallest of the clusters.\n\n### Note:\n###### The jpgs folder has to be copied into the vm for zeppelin to be able to read these, currently /home/saauser/upload is being provided as samba share \u0027upload\u0027.\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\nimport os\nfrom subprocess import call\nfrom pathlib import Path\n\nimg_path_hires_o \u003d z.textbox(\"Images folder:\",\"/home/saauser/upload/osprey/jpg/\")\nimg_path_hires \u003d img_path_hires_o+\"/\"\nuniq_ext \u003d os.path.basename(img_path_hires_o)\nimg_path \u003d \"/tmp/cache_\"+uniq_ext\npca_path \u003d \"/tmp/pca_\"+uniq_ext\nPath(pca_path).mkdir(parents\u003dTrue, exist_ok\u003dTrue) #make pca_path dir/ if it doesn\u0027t exist\n\noptions \u003d [(\"col\",\"JPG\"),(\"bw\",\"Mono\"), (\"corr\",\"Correct Images\"), (\"cacheclr\",\"Cache Clear\")]\nzval\u003d z.checkbox(\"Select Color or Mono-Channel Images\",options)\n\nif any(\"cacheclr\" in s for s in zval): #remove low res img folder if this flag is set\n    cret\u003dcall([\u0027rm\u0027,\u0027-rf\u0027,img_path])\n    if cret \u003d\u003d 0:\n        print(img_path,\": cleared\")\n    else:\n        print(img_path,\": Not cleared\")\ncret\u003dcall([\u0027rsync\u0027,\u0027-varuzpP\u0027,\u0027--delete\u0027,img_path_hires,img_path])\nif cret \u003d\u003d 0:\n    print(img_path_hires,\"-\u003e staged successfully in :\",img_path)\nelse:\n    print(img_path_hires,\"-\u003e failed to stage in :\",img_path)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\nimport random\nimport sys\nimport numpy as np\nfrom matplotlib.image import imread\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport glob\n\ndef clean_up(path):\n    clean_these \u003d glob.glob(os.path.join(path,\u0027._*\u0027))\n    if clean_these:\n        for f in clean_these:\n            fname \u003d f.rstrip() # or depending on situation: f.rstrip(\u0027\\n\u0027)\n            # or, if you get rid of os.chdir(path) above,\n            # fname \u003d os.path.join(path, f.rstrip())\n            if os.path.isfile(fname): # this makes the code more robust\n                os.remove(fname)\n\ndef resize_134(path):\n    dirs \u003d os.listdir( path )\n    new_ht \u003d 134\n    for img_p_nm in dirs:\n        img_p_nm \u003d os.path.join(path,img_p_nm)\n        #img_p_nm \u003d path+\"/\"+img_p_nm\n        #print(img_p_nm)\n        if img_p_nm \u003d\u003d os.path.join(path,\u0027.DS_Store\u0027):\n            continue\n        if os.path.isfile(img_p_nm):\n            im \u003d Image.open(img_p_nm)\n            new_wd \u003d int(round(im.size[0]/im.size[1]*new_ht,0))\n            if im.size[1] !\u003d 134:\n                resized_im \u003d im.resize((new_wd,new_ht), Image.ANTIALIAS)\n                resized_im.save(img_p_nm)\n\n\ndef load_images(folder):\n    images \u003d []\n    cnt\u003d0\n    for filename in os.listdir(folder):\n        img \u003d imread(os.path.join(folder,filename))\n        if any(\"corr\" in s for s in zval):\n            img \u003d np.clip(img,1,255) #\u003c\u003c\u003c\u003c rep zeroes with 1s  \u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\n            where_are_NaNs \u003d ~np.isfinite(img) #\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\n            img[where_are_NaNs] \u003d 1\n            if cnt \u003d\u003d 0:\n                print(\"\u003e\u003e\u003eInput images error corrected\u003c\u003c\u003c\")\n        if img is not None:\n            if any(\"col\" in s for s in zval):\n                if len(img.shape) \u003e 2: #only load color images\n                    images.append(filename)\n                    images.append(img)\n                    cnt +\u003d 1\n            else:\n                if not len(img.shape) \u003e 2: #only load bw images\n                    images.append(filename)\n                    images.append(img)\n                    cnt +\u003d 1\n    print(zval[0],\"images loaded:\",cnt)\n    return images\ndef bw_images(images):\n    images_bw \u003d []\n    bwcnt\u003d0\n    colcnt\u003d0\n    for idx in range(1,len(images), 2): # start at pos 1, step 2\n        images_bw.append(images[idx-1])  # copy over filename from prev\n        if(len(images[idx].shape)\u003e2): # otherwise assume it\u0027s grey scale already\n            image_sum \u003d images[idx].sum(axis\u003d2)\n            images_bw.append(image_sum/image_sum.max())\n            colcnt +\u003d 1\n        else: \n            images_bw.append(images[idx])\n            bwcnt +\u003d 1\n    print(\"Converted col-\u003ebw\",colcnt,\"Skipped bw-\u003ebw\",bwcnt)\n    return images_bw\n\nclean_up(img_path)\nresize_134(img_path)\nimages \u003d load_images(img_path)\nimages_bw \u003d bw_images(images)\nimages_np \u003d np.array(images,dtype\u003dobject)\nimages_bw_np \u003d np.array(images_bw,dtype\u003dobject)\n\n# E.g. i\u003d1 odd indices for images (even for image filenames)\ni \u003d random.randrange(1,len(images_np),2) # pick a random odd index from np_images[]\nimage_raw \u003d images_np[i]\nimage_bw \u003d images_bw_np[i]\n\n# Displaying the image\nplt.figure(figsize\u003d[12,8])\nplt.grid(False)\nif zval[0] \u003d\u003d \u0027col\u0027:\n    plt.imshow(image_raw)\nelse: plt.imshow(image_raw,cmap\u003dplt.cm.gray)\nz.show(plt, width\u003d\"400px\")\nprint(\"A randomly picked framesJPG:\",images_np.shape, images_np[i-1], \"img_size:\",image_raw.shape)\n# Displaying the bw image version\nplt.figure(figsize\u003d[12,8])\nplt.grid(False)\nplt.imshow(image_bw, cmap\u003dplt.cm.gray)\nz.show(plt, width\u003d\"400px\")\nplt.close()\nprint(\"images BW:\",images_bw_np.shape, images_bw_np[i-1], \"img_size:\",images_bw_np[i].shape)"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\nfrom sklearn.decomposition import PCA, IncrementalPCA\nfrom itertools import chain\n\ndef pca_img(images):\n    converted_data \u003d []\n    for idx in range(1,len(images), 2): # start at pos 1, step 2\n        converted_data.append(images[idx-1])  # copy over filename from prev\n        converted_data.append(pca.fit_transform(images[idx]))\n    return converted_data\ndef data_transformer(converted_data):\n    # takes pca n x 2 /per image transposes to 2 x n, then flatten as:\n    # pca00,pc01,..,pc0n, pca10,pca11,...pca1n (into a single row)\n    # per image for df creation in spark\n    # Ref only: for 2D dynamic arrays idx_td \u003d len(converted_data)//2 # dynamic array \n    # with two cols and half the rows. some_data \u003d [[] for _ in range(idx_td)]\n    \n    keys_data \u003d []\n    trans_data \u003d []\n    \n    for idx in range(1,len(converted_data),2): # start at pos 1, step 2\n        keys_data.append(converted_data[idx-1]) # copy over filename from prev\n        converted_data_transposed \u003d converted_data[idx].T \n        flattened_converted_data_transposed_ \u003d np.array(list(chain.from_iterable(converted_data_transposed)))\n        flattened_converted_data_transposed \u003d flattened_converted_data_transposed_.T\n        trans_data.append(flattened_converted_data_transposed)\n    return np.array(keys_data), np.array(trans_data)\n\npca \u003d PCA(2) # we need 2 principal components.\n\n# do pca on all the bw images reduce image_length to 2 cols\nconv_data \u003d np.array(pca_img(images_bw_np),dtype\u003dobject)\n\n# keys_data has the image filenames \u003c-\u003e to each row of trans_data[PCA01..PCA0n,PCA11,..PCA1n - a row/image]\nkeys_data, trans_data \u003d data_transformer(conv_data)\n\n#np.set_printoptions(suppress\u003dTrue)\n#print(keys_data.shape, keys_data, os.listdir(\"/home/saauser/upload/ngc/jpg\"))\n#print(trans_data.shape, trans_data)\n\n# Save the source filenames and PCA results to separate files (only for debugging if needed)\n#np.savetxt(\"/home/saauser/upload/ngc/pca/keys-all-jpg.csv\", keys_data, delimiter\u003d\",\", fmt\u003d\u0027%s\u0027)\n#np.savetxt(\"/home/saauser/upload/ngc/pca/pca-all-jpg.csv\", trans_data, delimiter\u003d\",\")\nnp.savetxt(os.path.join(pca_path,\"keys-all-jpg.csv\"), keys_data, delimiter\u003d\",\", fmt\u003d\u0027%s\u0027)\nnp.savetxt(os.path.join(pca_path,\"pca-all-jpg.csv\"), trans_data, delimiter\u003d\",\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nimport csv\nimport uuid\n\n\npca_out_file \u003d str(uuid.uuid4())+\".csv\"\npca_out_file_fullpath \u003d os.path.join(pca_path, pca_out_file)\n\nf \u003d open(pca_out_file_fullpath, \u0027w\u0027)\n\nwriter \u003d csv.writer(f)\nrows, cols \u003d trans_data.shape\nfor i in range(rows):\n    trans_keys_row \u003d np.append(trans_data[i], keys_data[i])\n    writer.writerow(trans_keys_row)\nf.close()\n\nz.put(\"pcaOutFile\",pca_out_file_fullpath) #Saved for Spark scala use in Load PCA Data -\u003e Spark DF\n"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nval ANSI_RESET \u003d \"\\u001B[0m\"\nval ANSI_BLACK \u003d \"\\u001B[30m\"\nval ANSI_RED \u003d \"\\u001B[31m\"\nval ANSI_GREEN \u003d \"\\u001B[32m\"\nval ANSI_YELLOW \u003d \"\\u001B[33m\"\nval ANSI_BLUE \u003d \"\\u001B[34m\"\nval ANSI_PURPLE \u003d \"\\u001B[35m\"\nval ANSI_CYAN \u003d \"\\u001B[36m\"\nval ANSI_WHITE \u003d \"\\u001B[37m\"\nprintln(ANSI_RESET)\n\nval pcaOutFile \u003d z.get(\"pcaOutFile\") \nprintln(pcaOutFile)\n\nval df \u003d spark.read.format(\"csv\").option(\"header\",\"false\").option(\"inferSchema\",\"true\").option(\"delimiter\",\",\")\n.load(\"file://\"+pcaOutFile)"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n\n// Run only if input image height is !\u003d 134 pixels\nval img_width \u003d df.columns.size - 1 // last col in df has image filename hence deducted\nval c2 \u003d img_width/2\n\nval x \u003d List.tabulate(c2) ( n \u003d\u003e s\"\"\"array(col(\"_c$n\"),col(\"_c${c2+n}\")).as(\"PCA$n\")\"\"\" )\n\nval y \u003d s\"\"\"col(\"_c${img_width}\").as(\"REF\"), \"\"\"\n\nval yx \u003d (y+x).replace(\"List(\",\"\")\nprintln(yx) "
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n\n//val cols \u003d df copy pasted from previous paragrapgh below (seem this is the only way to get this thing to work:\n//New copy-paste is only required if image height is !\u003d134\n\nval df1 \u003d df.select(col(\"_c268\").as(\"REF\"), array(col(\"_c0\"),col(\"_c134\")).as(\"PCA0\"), array(col(\"_c1\"),col(\"_c135\")).as(\"PCA1\"), array(col(\"_c2\"),col(\"_c136\")).as(\"PCA2\"), array(col(\"_c3\"),col(\"_c137\")).as(\"PCA3\"), array(col(\"_c4\"),col(\"_c138\")).as(\"PCA4\"), array(col(\"_c5\"),col(\"_c139\")).as(\"PCA5\"), array(col(\"_c6\"),col(\"_c140\")).as(\"PCA6\"), array(col(\"_c7\"),col(\"_c141\")).as(\"PCA7\"), array(col(\"_c8\"),col(\"_c142\")).as(\"PCA8\"), array(col(\"_c9\"),col(\"_c143\")).as(\"PCA9\"), array(col(\"_c10\"),col(\"_c144\")).as(\"PCA10\"), array(col(\"_c11\"),col(\"_c145\")).as(\"PCA11\"), array(col(\"_c12\"),col(\"_c146\")).as(\"PCA12\"), array(col(\"_c13\"),col(\"_c147\")).as(\"PCA13\"), array(col(\"_c14\"),col(\"_c148\")).as(\"PCA14\"), array(col(\"_c15\"),col(\"_c149\")).as(\"PCA15\"), array(col(\"_c16\"),col(\"_c150\")).as(\"PCA16\"), array(col(\"_c17\"),col(\"_c151\")).as(\"PCA17\"), array(col(\"_c18\"),col(\"_c152\")).as(\"PCA18\"), array(col(\"_c19\"),col(\"_c153\")).as(\"PCA19\"), array(col(\"_c20\"),col(\"_c154\")).as(\"PCA20\"), array(col(\"_c21\"),col(\"_c155\")).as(\"PCA21\"), array(col(\"_c22\"),col(\"_c156\")).as(\"PCA22\"), array(col(\"_c23\"),col(\"_c157\")).as(\"PCA23\"), array(col(\"_c24\"),col(\"_c158\")).as(\"PCA24\"), array(col(\"_c25\"),col(\"_c159\")).as(\"PCA25\"), array(col(\"_c26\"),col(\"_c160\")).as(\"PCA26\"), array(col(\"_c27\"),col(\"_c161\")).as(\"PCA27\"), array(col(\"_c28\"),col(\"_c162\")).as(\"PCA28\"), array(col(\"_c29\"),col(\"_c163\")).as(\"PCA29\"), array(col(\"_c30\"),col(\"_c164\")).as(\"PCA30\"), array(col(\"_c31\"),col(\"_c165\")).as(\"PCA31\"), array(col(\"_c32\"),col(\"_c166\")).as(\"PCA32\"), array(col(\"_c33\"),col(\"_c167\")).as(\"PCA33\"), array(col(\"_c34\"),col(\"_c168\")).as(\"PCA34\"), array(col(\"_c35\"),col(\"_c169\")).as(\"PCA35\"), array(col(\"_c36\"),col(\"_c170\")).as(\"PCA36\"), array(col(\"_c37\"),col(\"_c171\")).as(\"PCA37\"), array(col(\"_c38\"),col(\"_c172\")).as(\"PCA38\"), array(col(\"_c39\"),col(\"_c173\")).as(\"PCA39\"), array(col(\"_c40\"),col(\"_c174\")).as(\"PCA40\"), array(col(\"_c41\"),col(\"_c175\")).as(\"PCA41\"), array(col(\"_c42\"),col(\"_c176\")).as(\"PCA42\"), array(col(\"_c43\"),col(\"_c177\")).as(\"PCA43\"), array(col(\"_c44\"),col(\"_c178\")).as(\"PCA44\"), array(col(\"_c45\"),col(\"_c179\")).as(\"PCA45\"), array(col(\"_c46\"),col(\"_c180\")).as(\"PCA46\"), array(col(\"_c47\"),col(\"_c181\")).as(\"PCA47\"), array(col(\"_c48\"),col(\"_c182\")).as(\"PCA48\"), array(col(\"_c49\"),col(\"_c183\")).as(\"PCA49\"), array(col(\"_c50\"),col(\"_c184\")).as(\"PCA50\"), array(col(\"_c51\"),col(\"_c185\")).as(\"PCA51\"), array(col(\"_c52\"),col(\"_c186\")).as(\"PCA52\"), array(col(\"_c53\"),col(\"_c187\")).as(\"PCA53\"), array(col(\"_c54\"),col(\"_c188\")).as(\"PCA54\"), array(col(\"_c55\"),col(\"_c189\")).as(\"PCA55\"), array(col(\"_c56\"),col(\"_c190\")).as(\"PCA56\"), array(col(\"_c57\"),col(\"_c191\")).as(\"PCA57\"), array(col(\"_c58\"),col(\"_c192\")).as(\"PCA58\"), array(col(\"_c59\"),col(\"_c193\")).as(\"PCA59\"), array(col(\"_c60\"),col(\"_c194\")).as(\"PCA60\"), array(col(\"_c61\"),col(\"_c195\")).as(\"PCA61\"), array(col(\"_c62\"),col(\"_c196\")).as(\"PCA62\"), array(col(\"_c63\"),col(\"_c197\")).as(\"PCA63\"), array(col(\"_c64\"),col(\"_c198\")).as(\"PCA64\"), array(col(\"_c65\"),col(\"_c199\")).as(\"PCA65\"), array(col(\"_c66\"),col(\"_c200\")).as(\"PCA66\"), array(col(\"_c67\"),col(\"_c201\")).as(\"PCA67\"), array(col(\"_c68\"),col(\"_c202\")).as(\"PCA68\"), array(col(\"_c69\"),col(\"_c203\")).as(\"PCA69\"), array(col(\"_c70\"),col(\"_c204\")).as(\"PCA70\"), array(col(\"_c71\"),col(\"_c205\")).as(\"PCA71\"), array(col(\"_c72\"),col(\"_c206\")).as(\"PCA72\"), array(col(\"_c73\"),col(\"_c207\")).as(\"PCA73\"), array(col(\"_c74\"),col(\"_c208\")).as(\"PCA74\"), array(col(\"_c75\"),col(\"_c209\")).as(\"PCA75\"), array(col(\"_c76\"),col(\"_c210\")).as(\"PCA76\"), array(col(\"_c77\"),col(\"_c211\")).as(\"PCA77\"), array(col(\"_c78\"),col(\"_c212\")).as(\"PCA78\"), array(col(\"_c79\"),col(\"_c213\")).as(\"PCA79\"), array(col(\"_c80\"),col(\"_c214\")).as(\"PCA80\"), array(col(\"_c81\"),col(\"_c215\")).as(\"PCA81\"), array(col(\"_c82\"),col(\"_c216\")).as(\"PCA82\"), array(col(\"_c83\"),col(\"_c217\")).as(\"PCA83\"), array(col(\"_c84\"),col(\"_c218\")).as(\"PCA84\"), array(col(\"_c85\"),col(\"_c219\")).as(\"PCA85\"), array(col(\"_c86\"),col(\"_c220\")).as(\"PCA86\"), array(col(\"_c87\"),col(\"_c221\")).as(\"PCA87\"), array(col(\"_c88\"),col(\"_c222\")).as(\"PCA88\"), array(col(\"_c89\"),col(\"_c223\")).as(\"PCA89\"), array(col(\"_c90\"),col(\"_c224\")).as(\"PCA90\"), array(col(\"_c91\"),col(\"_c225\")).as(\"PCA91\"), array(col(\"_c92\"),col(\"_c226\")).as(\"PCA92\"), array(col(\"_c93\"),col(\"_c227\")).as(\"PCA93\"), array(col(\"_c94\"),col(\"_c228\")).as(\"PCA94\"), array(col(\"_c95\"),col(\"_c229\")).as(\"PCA95\"), array(col(\"_c96\"),col(\"_c230\")).as(\"PCA96\"), array(col(\"_c97\"),col(\"_c231\")).as(\"PCA97\"), array(col(\"_c98\"),col(\"_c232\")).as(\"PCA98\"), array(col(\"_c99\"),col(\"_c233\")).as(\"PCA99\"), array(col(\"_c100\"),col(\"_c234\")).as(\"PCA100\"), array(col(\"_c101\"),col(\"_c235\")).as(\"PCA101\"), array(col(\"_c102\"),col(\"_c236\")).as(\"PCA102\"), array(col(\"_c103\"),col(\"_c237\")).as(\"PCA103\"), array(col(\"_c104\"),col(\"_c238\")).as(\"PCA104\"), array(col(\"_c105\"),col(\"_c239\")).as(\"PCA105\"), array(col(\"_c106\"),col(\"_c240\")).as(\"PCA106\"), array(col(\"_c107\"),col(\"_c241\")).as(\"PCA107\"), array(col(\"_c108\"),col(\"_c242\")).as(\"PCA108\"), array(col(\"_c109\"),col(\"_c243\")).as(\"PCA109\"), array(col(\"_c110\"),col(\"_c244\")).as(\"PCA110\"), array(col(\"_c111\"),col(\"_c245\")).as(\"PCA111\"), array(col(\"_c112\"),col(\"_c246\")).as(\"PCA112\"), array(col(\"_c113\"),col(\"_c247\")).as(\"PCA113\"), array(col(\"_c114\"),col(\"_c248\")).as(\"PCA114\"), array(col(\"_c115\"),col(\"_c249\")).as(\"PCA115\"), array(col(\"_c116\"),col(\"_c250\")).as(\"PCA116\"), array(col(\"_c117\"),col(\"_c251\")).as(\"PCA117\"), array(col(\"_c118\"),col(\"_c252\")).as(\"PCA118\"), array(col(\"_c119\"),col(\"_c253\")).as(\"PCA119\"), array(col(\"_c120\"),col(\"_c254\")).as(\"PCA120\"), array(col(\"_c121\"),col(\"_c255\")).as(\"PCA121\"), array(col(\"_c122\"),col(\"_c256\")).as(\"PCA122\"), array(col(\"_c123\"),col(\"_c257\")).as(\"PCA123\"), array(col(\"_c124\"),col(\"_c258\")).as(\"PCA124\"), array(col(\"_c125\"),col(\"_c259\")).as(\"PCA125\"), array(col(\"_c126\"),col(\"_c260\")).as(\"PCA126\"), array(col(\"_c127\"),col(\"_c261\")).as(\"PCA127\"), array(col(\"_c128\"),col(\"_c262\")).as(\"PCA128\"), array(col(\"_c129\"),col(\"_c263\")).as(\"PCA129\"), array(col(\"_c130\"),col(\"_c264\")).as(\"PCA130\"), array(col(\"_c131\"),col(\"_c265\")).as(\"PCA131\"), array(col(\"_c132\"),col(\"_c266\")).as(\"PCA132\"), array(col(\"_c133\"),col(\"_c267\")).as(\"PCA133\"))\n\nz.show(df1)\n\n//create featuresArray\nval cols \u003d df1.columns.toArray.map(col(_).toString)\nval b \u003d cols.toBuffer\nb.remove(0)\nval featuresArray \u003d b.toArray\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nimport org.apache.spark.ml.linalg.Vectors\n\n// Run only if input image height is !\u003d 134 pixels\n\nval d2 \u003d df1.columns.size - 1 // first col in df1 has image filename hence deducted\n\n// Spark 2.0. For 1.x use mllib\n// https://spark.apache.org/docs/latest/sql-programming-guide.html#data-types\n//Ref https://stackoverflow.com/a/41091839/4106464\nval seqAsVector \u003d udf((xs: Seq[Double]) \u003d\u003e Vectors.dense(xs.toArray))\n\nval p \u003d List.tabulate(d2) ( n \u003d\u003e s\"\"\"seqAsVector(col(\"PCA$n\")).as(\"PCA$n\")\"\"\" )\n\nval q \u003d s\"\"\"col(\"REF\"), \"\"\"\n\nval qp \u003d (q+p).replace(\"List(\",\"\")\nprintln(qp) "
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nimport org.apache.spark.sql.functions.{col, udf}\n\nval df1_final \u003d df1.select(col(\"REF\"), seqAsVector(col(\"PCA0\")).as(\"PCA0\"), seqAsVector(col(\"PCA1\")).as(\"PCA1\"), seqAsVector(col(\"PCA2\")).as(\"PCA2\"), seqAsVector(col(\"PCA3\")).as(\"PCA3\"), seqAsVector(col(\"PCA4\")).as(\"PCA4\"), seqAsVector(col(\"PCA5\")).as(\"PCA5\"), seqAsVector(col(\"PCA6\")).as(\"PCA6\"), seqAsVector(col(\"PCA7\")).as(\"PCA7\"), seqAsVector(col(\"PCA8\")).as(\"PCA8\"), seqAsVector(col(\"PCA9\")).as(\"PCA9\"), seqAsVector(col(\"PCA10\")).as(\"PCA10\"), seqAsVector(col(\"PCA11\")).as(\"PCA11\"), seqAsVector(col(\"PCA12\")).as(\"PCA12\"), seqAsVector(col(\"PCA13\")).as(\"PCA13\"), seqAsVector(col(\"PCA14\")).as(\"PCA14\"), seqAsVector(col(\"PCA15\")).as(\"PCA15\"), seqAsVector(col(\"PCA16\")).as(\"PCA16\"), seqAsVector(col(\"PCA17\")).as(\"PCA17\"), seqAsVector(col(\"PCA18\")).as(\"PCA18\"), seqAsVector(col(\"PCA19\")).as(\"PCA19\"), seqAsVector(col(\"PCA20\")).as(\"PCA20\"), seqAsVector(col(\"PCA21\")).as(\"PCA21\"), seqAsVector(col(\"PCA22\")).as(\"PCA22\"), seqAsVector(col(\"PCA23\")).as(\"PCA23\"), seqAsVector(col(\"PCA24\")).as(\"PCA24\"), seqAsVector(col(\"PCA25\")).as(\"PCA25\"), seqAsVector(col(\"PCA26\")).as(\"PCA26\"), seqAsVector(col(\"PCA27\")).as(\"PCA27\"), seqAsVector(col(\"PCA28\")).as(\"PCA28\"), seqAsVector(col(\"PCA29\")).as(\"PCA29\"), seqAsVector(col(\"PCA30\")).as(\"PCA30\"), seqAsVector(col(\"PCA31\")).as(\"PCA31\"), seqAsVector(col(\"PCA32\")).as(\"PCA32\"), seqAsVector(col(\"PCA33\")).as(\"PCA33\"), seqAsVector(col(\"PCA34\")).as(\"PCA34\"), seqAsVector(col(\"PCA35\")).as(\"PCA35\"), seqAsVector(col(\"PCA36\")).as(\"PCA36\"), seqAsVector(col(\"PCA37\")).as(\"PCA37\"), seqAsVector(col(\"PCA38\")).as(\"PCA38\"), seqAsVector(col(\"PCA39\")).as(\"PCA39\"), seqAsVector(col(\"PCA40\")).as(\"PCA40\"), seqAsVector(col(\"PCA41\")).as(\"PCA41\"), seqAsVector(col(\"PCA42\")).as(\"PCA42\"), seqAsVector(col(\"PCA43\")).as(\"PCA43\"), seqAsVector(col(\"PCA44\")).as(\"PCA44\"), seqAsVector(col(\"PCA45\")).as(\"PCA45\"), seqAsVector(col(\"PCA46\")).as(\"PCA46\"), seqAsVector(col(\"PCA47\")).as(\"PCA47\"), seqAsVector(col(\"PCA48\")).as(\"PCA48\"), seqAsVector(col(\"PCA49\")).as(\"PCA49\"), seqAsVector(col(\"PCA50\")).as(\"PCA50\"), seqAsVector(col(\"PCA51\")).as(\"PCA51\"), seqAsVector(col(\"PCA52\")).as(\"PCA52\"), seqAsVector(col(\"PCA53\")).as(\"PCA53\"), seqAsVector(col(\"PCA54\")).as(\"PCA54\"), seqAsVector(col(\"PCA55\")).as(\"PCA55\"), seqAsVector(col(\"PCA56\")).as(\"PCA56\"), seqAsVector(col(\"PCA57\")).as(\"PCA57\"), seqAsVector(col(\"PCA58\")).as(\"PCA58\"), seqAsVector(col(\"PCA59\")).as(\"PCA59\"), seqAsVector(col(\"PCA60\")).as(\"PCA60\"), seqAsVector(col(\"PCA61\")).as(\"PCA61\"), seqAsVector(col(\"PCA62\")).as(\"PCA62\"), seqAsVector(col(\"PCA63\")).as(\"PCA63\"), seqAsVector(col(\"PCA64\")).as(\"PCA64\"), seqAsVector(col(\"PCA65\")).as(\"PCA65\"), seqAsVector(col(\"PCA66\")).as(\"PCA66\"), seqAsVector(col(\"PCA67\")).as(\"PCA67\"), seqAsVector(col(\"PCA68\")).as(\"PCA68\"), seqAsVector(col(\"PCA69\")).as(\"PCA69\"), seqAsVector(col(\"PCA70\")).as(\"PCA70\"), seqAsVector(col(\"PCA71\")).as(\"PCA71\"), seqAsVector(col(\"PCA72\")).as(\"PCA72\"), seqAsVector(col(\"PCA73\")).as(\"PCA73\"), seqAsVector(col(\"PCA74\")).as(\"PCA74\"), seqAsVector(col(\"PCA75\")).as(\"PCA75\"), seqAsVector(col(\"PCA76\")).as(\"PCA76\"), seqAsVector(col(\"PCA77\")).as(\"PCA77\"), seqAsVector(col(\"PCA78\")).as(\"PCA78\"), seqAsVector(col(\"PCA79\")).as(\"PCA79\"), seqAsVector(col(\"PCA80\")).as(\"PCA80\"), seqAsVector(col(\"PCA81\")).as(\"PCA81\"), seqAsVector(col(\"PCA82\")).as(\"PCA82\"), seqAsVector(col(\"PCA83\")).as(\"PCA83\"), seqAsVector(col(\"PCA84\")).as(\"PCA84\"), seqAsVector(col(\"PCA85\")).as(\"PCA85\"), seqAsVector(col(\"PCA86\")).as(\"PCA86\"), seqAsVector(col(\"PCA87\")).as(\"PCA87\"), seqAsVector(col(\"PCA88\")).as(\"PCA88\"), seqAsVector(col(\"PCA89\")).as(\"PCA89\"), seqAsVector(col(\"PCA90\")).as(\"PCA90\"), seqAsVector(col(\"PCA91\")).as(\"PCA91\"), seqAsVector(col(\"PCA92\")).as(\"PCA92\"), seqAsVector(col(\"PCA93\")).as(\"PCA93\"), seqAsVector(col(\"PCA94\")).as(\"PCA94\"), seqAsVector(col(\"PCA95\")).as(\"PCA95\"), seqAsVector(col(\"PCA96\")).as(\"PCA96\"), seqAsVector(col(\"PCA97\")).as(\"PCA97\"), seqAsVector(col(\"PCA98\")).as(\"PCA98\"), seqAsVector(col(\"PCA99\")).as(\"PCA99\"), seqAsVector(col(\"PCA100\")).as(\"PCA100\"), seqAsVector(col(\"PCA101\")).as(\"PCA101\"), seqAsVector(col(\"PCA102\")).as(\"PCA102\"), seqAsVector(col(\"PCA103\")).as(\"PCA103\"), seqAsVector(col(\"PCA104\")).as(\"PCA104\"), seqAsVector(col(\"PCA105\")).as(\"PCA105\"), seqAsVector(col(\"PCA106\")).as(\"PCA106\"), seqAsVector(col(\"PCA107\")).as(\"PCA107\"), seqAsVector(col(\"PCA108\")).as(\"PCA108\"), seqAsVector(col(\"PCA109\")).as(\"PCA109\"), seqAsVector(col(\"PCA110\")).as(\"PCA110\"), seqAsVector(col(\"PCA111\")).as(\"PCA111\"), seqAsVector(col(\"PCA112\")).as(\"PCA112\"), seqAsVector(col(\"PCA113\")).as(\"PCA113\"), seqAsVector(col(\"PCA114\")).as(\"PCA114\"), seqAsVector(col(\"PCA115\")).as(\"PCA115\"), seqAsVector(col(\"PCA116\")).as(\"PCA116\"), seqAsVector(col(\"PCA117\")).as(\"PCA117\"), seqAsVector(col(\"PCA118\")).as(\"PCA118\"), seqAsVector(col(\"PCA119\")).as(\"PCA119\"), seqAsVector(col(\"PCA120\")).as(\"PCA120\"), seqAsVector(col(\"PCA121\")).as(\"PCA121\"), seqAsVector(col(\"PCA122\")).as(\"PCA122\"), seqAsVector(col(\"PCA123\")).as(\"PCA123\"), seqAsVector(col(\"PCA124\")).as(\"PCA124\"), seqAsVector(col(\"PCA125\")).as(\"PCA125\"), seqAsVector(col(\"PCA126\")).as(\"PCA126\"), seqAsVector(col(\"PCA127\")).as(\"PCA127\"), seqAsVector(col(\"PCA128\")).as(\"PCA128\"), seqAsVector(col(\"PCA129\")).as(\"PCA129\"), seqAsVector(col(\"PCA130\")).as(\"PCA130\"), seqAsVector(col(\"PCA131\")).as(\"PCA131\"), seqAsVector(col(\"PCA132\")).as(\"PCA132\"), seqAsVector(col(\"PCA133\")).as(\"PCA133\"))\nz.show(df1_final)"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n//Convert the orginal dataframe into the format suitable for ML Clustering\nimport org.apache.spark.ml.feature.VectorAssembler\nimport org.apache.spark.ml.linalg.Vectors\n\nval assembler \u003d new VectorAssembler().setInputCols(featuresArray).setOutputCol(\"features\")\nval output \u003d assembler.transform(df1_final)\n//output.show\nval dataset \u003d output.select($\"REF\",$\"features\").toDF\n//dataset.show(false)\nprintln(\"Input DataFrame with features col added for ML\\n\u003d\u003d\u003d\\n\")\nz.show(dataset)"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nprintln(ANSI_RESET)\n//Clustering (Unsupervised)\nimport org.apache.spark.ml.clustering.KMeans\nimport org.apache.spark.ml.evaluation.ClusteringEvaluator\n\nval numClust_ \u003d z.textbox(\"Enter max number of clusters to use in kmeans:\",\"2\").toString\nval numClust \u003d numClust_.toInt\n\n// Trains a k-means model with numClust clusters specified.\nval kmeans \u003d new KMeans().setK(numClust).setSeed(1L)\nval model \u003d kmeans.fit(dataset)\n// Make predictions\nval predictions_raw \u003d model.transform(dataset)\nval predictions \u003d predictions_raw.select($\"REF\",$\"prediction\")\n\n//predictions.show(false)\n// Evaluate clustering by computing Silhouette score\nval evaluator \u003d new ClusteringEvaluator()\nval silhouette \u003d evaluator.evaluate(predictions_raw)\nprintln(s\"Silhouette with squared euclidean distance \u003d $silhouette\")\nprintln(\"predictions rows:\"+predictions.count+\" prediction cols:\"+predictions.columns.size)\nval clCenters \u003d model.clusterCenters\n//z.show(predictions)\n// no of categories\nval predictionsDF_g\u003d predictions_raw.groupBy(\"prediction\").count()\nz.show(predictionsDF_g)"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nval minClust_ \u003d z.textbox(\"Enter min number of items/cluster to display:\",\"1\").toString\nval minClust \u003d minClust_.toInt\nval maxClust_ \u003d z.textbox(\"Enter max number of items/cluster to display:\",\"1000000\").toString\nval maxClust \u003d maxClust_.toInt\n\nval predictionsDF_min \u003d  predictionsDF_g.filter($\"count\" \u003e\u003d minClust \u0026\u0026 $\"count\" \u003c\u003d maxClust )\n//z.show(predictions)\nz.show(predictionsDF_min)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n\nval tNum \u003d z.textbox(\"Enter a cluster no from Set Display Range chart. Then run Scene Inspector below to display the images in this cluster:\", \"0\" ).toString\nval pNum \u003d tNum.toInt\n\nval predictions_sel \u003d predictions.filter(col(\"prediction\") \u003d\u003d\u003d pNum)\n//val predictions_oth \u003d predictions.filter(col(\"prediction\") \u003d!\u003d pNum)\nval listREF\u003dpredictions_sel.select(\"REF\").map(f\u003d\u003ef.getString(0)).collect.toList\n//val listOTH\u003dpredictions_oth.select(\"REF\").map(f\u003d\u003ef.getString(0)).collect.toList\nz.put(\"listRef\",listREF)\n//z.put(\"listOth\", listOTH)\nz.put(\"pNum\",pNum)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nclass color:\n   PURPLE \u003d \u0027\\033[95m\u0027\n   CYAN \u003d \u0027\\033[96m\u0027\n   DARKCYAN \u003d \u0027\\033[36m\u0027\n   BLUE \u003d \u0027\\033[94m\u0027\n   GREEN \u003d \u0027\\033[92m\u0027\n   YELLOW \u003d \u0027\\033[93m\u0027\n   RED \u003d \u0027\\033[91m\u0027\n   BOLD \u003d \u0027\\033[1m\u0027\n   UNDERLINE \u003d \u0027\\033[4m\u0027\n   END \u003d \u0027\\033[0m\u0027\n#imgfilename \u003d z.textbox(\"Enter image filename.ext:\")\n\nlistRef \u003d z.get(\"listRef\")\n\npylistRef \u003d [listRef.apply(i) for i in range(listRef.size())]\n\ndef find_img(imgfile):\n    for i in range(0, len(images_bw),2):\n        if imgfile \u003d\u003d images[i]:\n            idx \u003d i\n            img \u003d images[i]\n    return idx\ndef disp_img(listRef):\n    idx \u003d find_img(rand_pick)\n    image_bw \u003d images[idx+1]\n    #print(idx//2, images[idx]) #halved as images are stored in every 2nd position im images[]\n    # Displaying the image\n    plt.figure(figsize\u003d[12,8])\n    plt.grid(False)\n    plt.imshow(image_bw,cmap\u003dplt.cm.gray)\n    print(color.PURPLE+\"Max four Random Picks from Cluster No:\"+color.END,z.get(\"pNum\"),\"\\t\\n\",rand_pick)\n    z.show(plt, width\u003d\"550px\")\n    return idx\ndef disp_img_multi(listRef):\n    f, axarr \u003d plt.subplots(2,2)\n    f.set_figheight(8)\n    f.set_figwidth(12)\n    for ax in f.get_axes(): #label outer axis only \n        #ref https://matplotlib.org/3.1.1/gallery/subplots_axes_and_figures/subplots_demo.html\n        ax.label_outer()\n    idx \u003d []\n    for i in range(4):\n        idx.append(find_img(rand_picks[i]))\n    k \u003d 0\n    for i in range(len(axarr)): # hide grid\n        for j in range(len(axarr[i])):\n            axarr[i,j].grid(False)\n            axarr[i,j].imshow(images[idx[k]+1],cmap\u003dplt.cm.gray)\n            k +\u003d 1\n    print(color.PURPLE+\"Max four Random Picks from Cluster No:\"+color.END,z.get(\"pNum\"),\"\\t\\n\",rand_picks[0],rand_picks[1],\"\\n\",rand_picks[2],rand_picks[3])\n    z.show(plt)\n    plt.close\n    return idx\ndef disp_sca(idx,listRef):\n    image_bw \u003d images_bw[idx+1]\n    #print(idx//2, images[idx]) #halved as images are stored in every 2nd position im images[]\n    # Displaying the image\n    plt.figure(figsize\u003d[12,8])\n    plt.scatter(conv_data[idx+1][:, 0], conv_data[idx+1][:, 1], s\u003d15)\n    print(\"(\",rand_pick,\")\")\n    z.show(plt, width\u003d\"550px\")\ndef disp_sca_multi(idx, listRef):\n    plt.style.use(\u0027seaborn-whitegrid\u0027)\n    f, axarr \u003d plt.subplots(2,2)\n    f.set_figheight(8)\n    f.set_figwidth(12)\n    f.suptitle(\"Corresponding PCA Scatter Plots\")\n    for ax in f.get_axes():\n        ax.label_outer()\n    k \u003d 0\n    for i in range(len(axarr)):\n        for j in range(len(axarr[i])):\n            axarr[i,j].scatter(conv_data[idx[k]+1][:, 0], conv_data[idx[k]+1][:, 1], s\u003d15)\n            axarr[i,j].set(xlabel\u003d\u0027PC-1\u0027,ylabel\u003d\u0027PC-2\u0027)\n            #print(conv_data[idx[k]])\n            k +\u003d 1\n    print(\"(\",rand_picks[0],rand_picks[1],rand_picks[2],rand_picks[3],\")\")\n    z.show(plt)\n    plt.close\n####################################################\nimport random\nif len(pylistRef) \u003e 4:\n    rand_picks \u003d random.sample(pylistRef, 4) #pick four img filenames randomly\nelse:        \n    rand_pick \u003d random.choice(pylistRef) #pick one img filenames randomly\nif len(pylistRef) \u003e 4:\n    idx \u003d disp_img_multi(pylistRef)\nelse:\n    idx \u003d disp_img(pylistRef)\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nprintln(\"%html \u003cvideo width\u003d\\\"320\\\" height\u003d\\\"240\\\" controls\u003e \u003csource src\u003d\\\"http://bigva224win.local/gone_wt_wind.mp4\\\" type\u003d\\\"video/mp4\\\"\u003e \u003c/video\u003e\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n"
    }
  ]
}